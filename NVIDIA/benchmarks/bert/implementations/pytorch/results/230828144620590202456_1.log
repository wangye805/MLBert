+ echo 'Beginning trial 1 of 1'
Beginning trial 1 of 1
+ '[' 1 -eq 1 ']'
+ sync
+ sudo /sbin/sysctl vm.drop_caches=3
vm.drop_caches = 3
+ docker exec -it yewang_language_model python -c '
from mlperf_logger import mllogger
mllogger.event(key=mllogger.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1693234016328, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
+ docker exec -it --env=BATCHSIZE --env=CONTAINER_PRELOAD_LUSTRE --env=DGXHT --env=DGXNGPU --env=DGXNNODES --env=DGXNSOCKET --env=DGXSOCKETCORES --env=DGXSYSTEM --env=EVAL_ITER_SAMPLES --env=EVAL_ITER_START_SAMPLES --env=EXTRA_PARAMS --env=GRADIENT_STEPS --env=INIT_LOSS_SCALE --env=LR --env=MAX_SAMPLES_TERMINATION --env=MAX_STEPS --env=OPT_LAMB_BETA_1 --env=OPT_LAMB_BETA_2 --env=PACKING_FACTOR --env=PHASE --env=SLURM_NTASKS --env=START_WARMUP_STEP --env=WALLTIME --env=WALLTIME_MINUTES --env=WARMUP_STEPS --env=WEIGHT_DECAY_RATE --env=SEED yewang_language_model python -m torch.distributed.run --standalone --no_python --nproc_per_node=8 ./run_and_time.sh
master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Run vars: id 22807 gpus 8 mparams ''
Run vars: id 31797 gpus 8 mparams ''
STARTING TIMING RUN AT 2023-08-28 02:46:58 PM
STARTING TIMING RUN AT 2023-08-28 02:46:58 PM
Run vars: id 31074 gpus 8 mparams ''
STARTING TIMING RUN AT 2023-08-28 02:46:58 PM
Run vars: id 13681 gpus 8 mparams ''
STARTING TIMING RUN AT 2023-08-28 02:46:58 PM
Run vars: id 19663 gpus 8 mparams ''
STARTING TIMING RUN AT 2023-08-28 02:46:58 PM
Run vars: id 4851 gpus 8 mparams ''
STARTING TIMING RUN AT 2023-08-28 02:46:58 PM
Run vars: id 1327 gpus 8 mparams ''
STARTING TIMING RUN AT 2023-08-28 02:46:58 PM
Run vars: id 3821 gpus 8 mparams ''
STARTING TIMING RUN AT 2023-08-28 02:46:58 PM
/usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
  warnings.warn(msg, DeprecatedFeatureWarning)
/usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
  warnings.warn(msg, DeprecatedFeatureWarning)
/usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
  warnings.warn(msg, DeprecatedFeatureWarning)
/usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
  warnings.warn(msg, DeprecatedFeatureWarning)
/usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
  warnings.warn(msg, DeprecatedFeatureWarning)
/usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
  warnings.warn(msg, DeprecatedFeatureWarning)
/usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
  warnings.warn(msg, DeprecatedFeatureWarning)
/usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
  warnings.warn(msg, DeprecatedFeatureWarning)
Traceback (most recent call last):
  File "/workspace/bert/run_pretraining.py", line 65, in <module>
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/workspace/bert/run_pretraining.py", line 65, in <module>
    Traceback (most recent call last):
  File "/workspace/bert/run_pretraining.py", line 65, in <module>
Traceback (most recent call last):
  File "/workspace/bert/run_pretraining.py", line 65, in <module>
  File "/workspace/bert/run_pretraining.py", line 65, in <module>
  File "/workspace/bert/run_pretraining.py", line 65, in <module>
from modeling import BertConfig  File "/workspace/bert/run_pretraining.py", line 65, in <module>
  File "/workspace/bert/run_pretraining.py", line 65, in <module>

  File "/workspace/bert/modeling.py", line 53, in <module>
        from transformer_engine.pytorch import fp8_autocastfrom modeling import BertConfig

  File "/usr/local/lib/python3.8/dist-packages/transformer_engine/pytorch/__init__.py", line 11, in <module>
  File "/workspace/bert/modeling.py", line 53, in <module>
        from modeling import BertConfigfrom modeling import BertConfig        
    
    from modeling import BertConfigfrom modeling import BertConfig  File "/workspace/bert/modeling.py", line 53, in <module>
from modeling import BertConfig  File "/workspace/bert/modeling.py", line 53, in <module>
from modeling import BertConfig



  File "/workspace/bert/modeling.py", line 53, in <module>
  File "/workspace/bert/modeling.py", line 53, in <module>
  File "/workspace/bert/modeling.py", line 53, in <module>
      File "/workspace/bert/modeling.py", line 53, in <module>
from transformer_engine.pytorch import fp8_autocast
  File "/usr/local/lib/python3.8/dist-packages/transformer_engine/pytorch/__init__.py", line 11, in <module>
    from transformer_engine.pytorch import fp8_autocast    
from transformer_engine.pytorch import fp8_autocast      File "/usr/local/lib/python3.8/dist-packages/transformer_engine/pytorch/__init__.py", line 11, in <module>

from transformer_engine.pytorch import fp8_autocast    
      File "/usr/local/lib/python3.8/dist-packages/transformer_engine/pytorch/__init__.py", line 11, in <module>
from transformer_engine.pytorch import fp8_autocast    from transformer_engine.pytorch import fp8_autocast  File "/usr/local/lib/python3.8/dist-packages/transformer_engine/pytorch/__init__.py", line 11, in <module>

from transformer_engine.pytorch import fp8_autocast
  File "/usr/local/lib/python3.8/dist-packages/transformer_engine/pytorch/__init__.py", line 11, in <module>

  File "/usr/local/lib/python3.8/dist-packages/transformer_engine/pytorch/__init__.py", line 11, in <module>
  File "/usr/local/lib/python3.8/dist-packages/transformer_engine/pytorch/__init__.py", line 11, in <module>
                    from .attention import DotProductAttention    from .attention import DotProductAttention        from .attention import DotProductAttentionfrom .attention import DotProductAttentionfrom .attention import DotProductAttention
from .attention import DotProductAttention
from .attention import DotProductAttentionfrom .attention import DotProductAttention


  File "/usr/local/lib/python3.8/dist-packages/transformer_engine/pytorch/attention.py", line 51, in <module>

  File "/usr/local/lib/python3.8/dist-packages/transformer_engine/pytorch/attention.py", line 51, in <module>


  File "/usr/local/lib/python3.8/dist-packages/transformer_engine/pytorch/attention.py", line 51, in <module>
  File "/usr/local/lib/python3.8/dist-packages/transformer_engine/pytorch/attention.py", line 51, in <module>
  File "/usr/local/lib/python3.8/dist-packages/transformer_engine/pytorch/attention.py", line 51, in <module>
  File "/usr/local/lib/python3.8/dist-packages/transformer_engine/pytorch/attention.py", line 51, in <module>
  File "/usr/local/lib/python3.8/dist-packages/transformer_engine/pytorch/attention.py", line 51, in <module>
  File "/usr/local/lib/python3.8/dist-packages/transformer_engine/pytorch/attention.py", line 51, in <module>
            from flash_attn.flash_attn_interface import flash_attn_varlen_func as flash_attn_forward_func # pylint: disable=no-name-in-module            from flash_attn.flash_attn_interface import flash_attn_varlen_func as flash_attn_forward_func # pylint: disable=no-name-in-modulefrom flash_attn.flash_attn_interface import flash_attn_varlen_func as flash_attn_forward_func # pylint: disable=no-name-in-module
    from flash_attn.flash_attn_interface import flash_attn_varlen_func as flash_attn_forward_func # pylint: disable=no-name-in-modulefrom flash_attn.flash_attn_interface import flash_attn_varlen_func as flash_attn_forward_func # pylint: disable=no-name-in-modulefrom flash_attn.flash_attn_interface import flash_attn_varlen_func as flash_attn_forward_func # pylint: disable=no-name-in-module

  File "/usr/local/lib/python3.8/dist-packages/flash_attn/__init__.py", line 3, in <module>
from flash_attn.flash_attn_interface import flash_attn_varlen_func as flash_attn_forward_func # pylint: disable=no-name-in-module

    
  File "/usr/local/lib/python3.8/dist-packages/flash_attn/__init__.py", line 3, in <module>
  File "/usr/local/lib/python3.8/dist-packages/flash_attn/__init__.py", line 3, in <module>

  File "/usr/local/lib/python3.8/dist-packages/flash_attn/__init__.py", line 3, in <module>
  File "/usr/local/lib/python3.8/dist-packages/flash_attn/__init__.py", line 3, in <module>
from flash_attn.flash_attn_interface import flash_attn_varlen_func as flash_attn_forward_func # pylint: disable=no-name-in-module  File "/usr/local/lib/python3.8/dist-packages/flash_attn/__init__.py", line 3, in <module>
  File "/usr/local/lib/python3.8/dist-packages/flash_attn/__init__.py", line 3, in <module>

  File "/usr/local/lib/python3.8/dist-packages/flash_attn/__init__.py", line 3, in <module>
                            from flash_attn.flash_attn_interface import (from flash_attn.flash_attn_interface import (from flash_attn.flash_attn_interface import (
      File "/usr/local/lib/python3.8/dist-packages/flash_attn/flash_attn_interface.py", line 7, in <module>
from flash_attn.flash_attn_interface import (from flash_attn.flash_attn_interface import (from flash_attn.flash_attn_interface import (from flash_attn.flash_attn_interface import (

  File "/usr/local/lib/python3.8/dist-packages/flash_attn/flash_attn_interface.py", line 7, in <module>
from flash_attn.flash_attn_interface import (



  File "/usr/local/lib/python3.8/dist-packages/flash_attn/flash_attn_interface.py", line 7, in <module>

  File "/usr/local/lib/python3.8/dist-packages/flash_attn/flash_attn_interface.py", line 7, in <module>
  File "/usr/local/lib/python3.8/dist-packages/flash_attn/flash_attn_interface.py", line 7, in <module>
  File "/usr/local/lib/python3.8/dist-packages/flash_attn/flash_attn_interface.py", line 7, in <module>
  File "/usr/local/lib/python3.8/dist-packages/flash_attn/flash_attn_interface.py", line 7, in <module>
  File "/usr/local/lib/python3.8/dist-packages/flash_attn/flash_attn_interface.py", line 7, in <module>
                    import flash_attn_2_cuda as flash_attn_cudaimport flash_attn_2_cuda as flash_attn_cudaimport flash_attn_2_cuda as flash_attn_cuda    import flash_attn_2_cuda as flash_attn_cuda    import flash_attn_2_cuda as flash_attn_cuda

    
import flash_attn_2_cuda as flash_attn_cuda
ImportErrorimport flash_attn_2_cuda as flash_attn_cuda
ImportErrorimport flash_attn_2_cuda as flash_attn_cudaImportError
: ImportError
: 
ImportError: ImportError/usr/local/lib/python3.8/dist-packages/flash_attn_2_cuda.cpython-38-x86_64-linux-gnu.so: undefined symbol: _ZN3c104cuda9SetDeviceEi: ImportError/usr/local/lib/python3.8/dist-packages/flash_attn_2_cuda.cpython-38-x86_64-linux-gnu.so: undefined symbol: _ZN3c104cuda9SetDeviceEi: ImportError/usr/local/lib/python3.8/dist-packages/flash_attn_2_cuda.cpython-38-x86_64-linux-gnu.so: undefined symbol: _ZN3c104cuda9SetDeviceEi: 
/usr/local/lib/python3.8/dist-packages/flash_attn_2_cuda.cpython-38-x86_64-linux-gnu.so: undefined symbol: _ZN3c104cuda9SetDeviceEi: 
/usr/local/lib/python3.8/dist-packages/flash_attn_2_cuda.cpython-38-x86_64-linux-gnu.so: undefined symbol: _ZN3c104cuda9SetDeviceEi: 
/usr/local/lib/python3.8/dist-packages/flash_attn_2_cuda.cpython-38-x86_64-linux-gnu.so: undefined symbol: _ZN3c104cuda9SetDeviceEi
/usr/local/lib/python3.8/dist-packages/flash_attn_2_cuda.cpython-38-x86_64-linux-gnu.so: undefined symbol: _ZN3c104cuda9SetDeviceEi
/usr/local/lib/python3.8/dist-packages/flash_attn_2_cuda.cpython-38-x86_64-linux-gnu.so: undefined symbol: _ZN3c104cuda9SetDeviceEi


ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 244) of binary: ./run_and_time.sh
Traceback (most recent call last):
  File "/usr/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 798, in <module>
    main()
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 794, in main
    run(args)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py", line 250, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
./run_and_time.sh FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-08-28_14:47:08
  host      : GPU8518
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 248)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2023-08-28_14:47:08
  host      : GPU8518
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 254)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2023-08-28_14:47:08
  host      : GPU8518
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 266)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2023-08-28_14:47:08
  host      : GPU8518
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 277)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2023-08-28_14:47:08
  host      : GPU8518
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 286)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2023-08-28_14:47:08
  host      : GPU8518
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 296)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2023-08-28_14:47:08
  host      : GPU8518
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 307)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-08-28_14:47:08
  host      : GPU8518
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 244)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
